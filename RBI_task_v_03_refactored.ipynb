{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7dfadb7",
   "metadata": {},
   "source": [
    "# RBI Task Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47274db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost shap python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3893205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4effae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"Handle data cleaning and feature engineering.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_value(x):\n",
    "        if isinstance(x, str):\n",
    "            x = re.sub(r\"[^0-9,]+\", \"\", x)\n",
    "            x = x.replace(',', '.')\n",
    "        return x\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        target_mapping = {\"Y\": 1, \"N\": 0}\n",
    "        if 'Mortgage_YN' in data.columns:\n",
    "            data['target'] = data['Mortgage_YN'].map(target_mapping)\n",
    "            data.drop(columns=['Mortgage_YN'], inplace=True)\n",
    "        if 'Cocunut' in data.columns:\n",
    "            data.drop(columns=['Cocunut'], inplace=True)\n",
    "\n",
    "        if 'AGE_AT_ORIGINATION' in data.columns:\n",
    "            condition_target_1 = data['target'] == 1\n",
    "            data.loc[condition_target_1, 'AGE'] = data.loc[condition_target_1, 'AGE_AT_ORIGINATION']\n",
    "            data.drop(columns=['AGE_AT_ORIGINATION'], inplace=True)\n",
    "\n",
    "        for col in ['CURRENT_BALANCE_EUR', 'CUST_INCOME', 'CURRENT_ADDRESS_DATE',\n",
    "                    'CURRENT_JOB_DATE', 'CURRENT_WITH_BANK_DATE']:\n",
    "            if col in data.columns:\n",
    "                tmp = data[col].apply(self.clean_value)\n",
    "                data[col] = pd.to_numeric(tmp, errors='coerce')\n",
    "        return data\n",
    "\n",
    "    def encode(self, train, test):\n",
    "        cat_cols = train.select_dtypes(exclude=np.number).columns\n",
    "        for col in cat_cols:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(list(train[col].astype(str)) + list(test[col].astype(str)))\n",
    "            train[col] = le.transform(train[col].astype(str))\n",
    "            test[col] = le.transform(test[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "        return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52befaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw = pd.read_csv(\"Retail data.csv\", delimiter=';')\n",
    "preprocessor = DataPreprocessor()\n",
    "data = preprocessor.preprocess(raw.copy())\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "X_train = train_df.drop('target', axis=1)\n",
    "y_train = train_df['target']\n",
    "X_test = test_df.drop('target', axis=1)\n",
    "y_test = test_df['target']\n",
    "X_train, X_test = preprocessor.encode(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MortgageModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.best_params = None\n",
    "\n",
    "    def _objective(self, params):\n",
    "        clf = CatBoostClassifier(\n",
    "            iterations=int(params['iterations']),\n",
    "            depth=int(params['depth']),\n",
    "            learning_rate=params['learning_rate'],\n",
    "            l2_leaf_reg=int(params['l2_leaf_reg']),\n",
    "            border_count=int(params['border_count']),\n",
    "            loss_function='Logloss',\n",
    "            verbose=False\n",
    "        )\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=5).mean()\n",
    "        return {'loss': 1 - score, 'status': STATUS_OK}\n",
    "\n",
    "    def tune_hyperparameters(self):\n",
    "        space = {\n",
    "            'learning_rate': hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "            'iterations': hp.quniform('iterations', 50, 300, 1),\n",
    "            'depth': hp.quniform('depth', 2, 8, 1),\n",
    "            'l2_leaf_reg': hp.quniform('l2_leaf_reg', 1, 10, 1),\n",
    "            'border_count': hp.quniform('border_count', 5, 255, 5),\n",
    "        }\n",
    "        trials = Trials()\n",
    "        self.best_params = fmin(fn=self._objective, space=space, algo=tpe.suggest,\n",
    "                                max_evals=50, trials=trials)\n",
    "        return self.best_params\n",
    "\n",
    "    def fit(self):\n",
    "        params = {k:int(v) if k in ['iterations','depth','l2_leaf_reg','border_count'] else v\n",
    "                  for k,v in self.best_params.items()}\n",
    "        self.model = CatBoostClassifier(**params, loss_function='Logloss', verbose=False)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        joblib.dump(self.model, 'catboost_model.pkl')\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_proba = self.model.predict_proba(X_test)[:,1]\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.show()\n",
    "        return y_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MortgageModel()\n",
    "model.tune_hyperparameters()\n",
    "model.fit()\n",
    "y_proba = model.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0975bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explanations\n",
    "explainer = shap.TreeExplainer(model.model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "plt.savefig('summary_plot.png')\n",
    "\n",
    "prs = Presentation()\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "slide.shapes.title.text = 'SHAP Summary'\n",
    "left = Inches(1)\n",
    "top = Inches(1)\n",
    "slide.shapes.add_picture('summary_plot.png', left, top, width=Inches(6))\n",
    "prs.save('my_presentation.pptx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on new data\n",
    "new_data = pd.read_csv(\"Potential Customers.csv\", delimiter=';')\n",
    "new_data = preprocessor.preprocess(new_data)\n",
    "for col, le in preprocessor.label_encoders.items():\n",
    "    if col in new_data.columns:\n",
    "        new_data[col] = le.transform(new_data[col].astype(str))\n",
    "new_pred = model.model.predict(new_data)\n",
    "new_data['Model_Mortgage Prediction'] = new_pred\n",
    "new_data.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
