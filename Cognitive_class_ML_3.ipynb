{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cognitive_class_ML_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelprinc/Python/blob/master/Cognitive_class_ML_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GbA-4fi692J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.cluster import DBSCAN \n",
        "from sklearn.datasets.samples_generator import make_blobs \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "def createDataPoints(centroidLocation, numSamples, clusterDeviation):\n",
        "    # Create random data and store in feature matrix X and response vector y.\n",
        "    X, y = make_blobs(n_samples=numSamples, centers=centroidLocation, \n",
        "                                cluster_std=clusterDeviation)\n",
        "    \n",
        "    # Standardize features by removing the mean and scaling to unit variance\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "    return X, y\n",
        "\n",
        "X, y = createDataPoints([[4,3], [2,-1], [-1,4]] , 1500, 0.5)\n",
        "\n",
        "epsilon = 0.3\n",
        "minimumSamples = 7\n",
        "db = DBSCAN(eps=epsilon, min_samples=minimumSamples).fit(X)\n",
        "labels = db.labels_\n",
        "labels\n",
        "\n",
        "# Firts, create an array of booleans using the labels from db.\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "core_samples_mask\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_clusters_\n",
        "\n",
        "# Remove repetition in labels by turning it into a set.\n",
        "unique_labels = set(labels)\n",
        "unique_labels\n",
        "\n",
        "# Create colors for the clusters.\n",
        "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
        "colors\n",
        "\n",
        "# Plot the points with colors\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        # Black used for noise.\n",
        "        col = 'k'\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "\n",
        "    # Plot the datapoints that are clustered\n",
        "    xy = X[class_member_mask & core_samples_mask]\n",
        "    plt.scatter(xy[:, 0], xy[:, 1],s=50, c=col, marker=u'o', alpha=0.5)\n",
        "\n",
        "    # Plot the outliers\n",
        "    xy = X[class_member_mask & ~core_samples_mask]\n",
        "    plt.scatter(xy[:, 0], xy[:, 1],s=50, c=col, marker=u'o', alpha=0.5)\n",
        "\n",
        "from sklearn.cluster import KMeans \n",
        "k = 3\n",
        "k_means3 = KMeans(init = \"k-means++\", n_clusters = k, n_init = 12)\n",
        "k_means3.fit(X)\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "for k, col in zip(range(k), colors):\n",
        "    my_members = (k_means3.labels_ == k)\n",
        "    plt.scatter(X[my_members, 0], X[my_members, 1],  c=col, marker=u'o', alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgU-ERZJGlHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O weather-stations20140101-20141231.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/weather-stations20140101-20141231.csv\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "filename='weather-stations20140101-20141231.csv'\n",
        "\n",
        "#Read csv\n",
        "pdf = pd.read_csv(filename)\n",
        "pdf.head(5)\n",
        "\n",
        "pdf = pdf[pd.notnull(pdf[\"Tm\"])]\n",
        "pdf = pdf.reset_index(drop=True)\n",
        "pdf.head(5)\n",
        "\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "%matplotlib inline\n",
        "rcParams['figure.figsize'] = (14,10)\n",
        "\n",
        "llon=-140\n",
        "ulon=-50\n",
        "llat=40\n",
        "ulat=65\n",
        "\n",
        "pdf = pdf[(pdf['Long'] > llon) & (pdf['Long'] < ulon) & (pdf['Lat'] > llat) &(pdf['Lat'] < ulat)]\n",
        "\n",
        "my_map = Basemap(projection='merc',\n",
        "            resolution = 'l', area_thresh = 1000.0,\n",
        "            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
        "            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n",
        "\n",
        "my_map.drawcoastlines()\n",
        "my_map.drawcountries()\n",
        "# my_map.drawmapboundary()\n",
        "my_map.fillcontinents(color = 'white', alpha = 0.3)\n",
        "my_map.shadedrelief()\n",
        "\n",
        "# To collect data based on stations        \n",
        "\n",
        "xs,ys = my_map(np.asarray(pdf.Long), np.asarray(pdf.Lat))\n",
        "pdf['xm']= xs.tolist()\n",
        "pdf['ym'] =ys.tolist()\n",
        "\n",
        "#Visualization1\n",
        "for index,row in pdf.iterrows():\n",
        "#   x,y = my_map(row.Long, row.Lat)\n",
        "   my_map.plot(row.xm, row.ym,markerfacecolor =([1,0,0]),  marker='o', markersize= 5, alpha = 0.75)\n",
        "#plt.text(x,y,stn)\n",
        "plt.show()\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "import sklearn.utils\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sklearn.utils.check_random_state(1000)\n",
        "Clus_dataSet = pdf[['xm','ym']]\n",
        "Clus_dataSet = np.nan_to_num(Clus_dataSet)\n",
        "Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)\n",
        "\n",
        "# Compute DBSCAN\n",
        "db = DBSCAN(eps=0.15, min_samples=10).fit(Clus_dataSet)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = db.labels_\n",
        "pdf[\"Clus_Db\"]=labels\n",
        "\n",
        "realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)\n",
        "clusterNum = len(set(labels)) \n",
        "\n",
        "\n",
        "# A sample of clusters\n",
        "pdf[[\"Stn_Name\",\"Tx\",\"Tm\",\"Clus_Db\"]].head(5)\n",
        "\n",
        "set(labels)\n",
        "\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "%matplotlib inline\n",
        "rcParams['figure.figsize'] = (14,10)\n",
        "\n",
        "my_map = Basemap(projection='merc',\n",
        "            resolution = 'l', area_thresh = 1000.0,\n",
        "            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
        "            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n",
        "\n",
        "my_map.drawcoastlines()\n",
        "my_map.drawcountries()\n",
        "#my_map.drawmapboundary()\n",
        "my_map.fillcontinents(color = 'white', alpha = 0.3)\n",
        "my_map.shadedrelief()\n",
        "\n",
        "# To create a color map\n",
        "colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))\n",
        "\n",
        "\n",
        "\n",
        "#Visualization1\n",
        "for clust_number in set(labels):\n",
        "    c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])\n",
        "    clust_set = pdf[pdf.Clus_Db == clust_number]                    \n",
        "    my_map.scatter(clust_set.xm, clust_set.ym, color =c,  marker='o', s= 20, alpha = 0.85)\n",
        "    if clust_number != -1:\n",
        "        cenx=np.mean(clust_set.xm) \n",
        "        ceny=np.mean(clust_set.ym) \n",
        "        plt.text(cenx,ceny,str(clust_number), fontsize=25, color='red',)\n",
        "        print (\"Cluster \"+str(clust_number)+', Avg Temp: '+ str(np.mean(clust_set.Tm)))\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "import sklearn.utils\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sklearn.utils.check_random_state(1000)\n",
        "Clus_dataSet = pdf[['xm','ym','Tx','Tm','Tn']]\n",
        "Clus_dataSet = np.nan_to_num(Clus_dataSet)\n",
        "Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)\n",
        "\n",
        "# Compute DBSCAN\n",
        "db = DBSCAN(eps=0.3, min_samples=10).fit(Clus_dataSet)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = db.labels_\n",
        "pdf[\"Clus_Db\"]=labels\n",
        "\n",
        "realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)\n",
        "clusterNum = len(set(labels)) \n",
        "\n",
        "\n",
        "# A sample of clusters\n",
        "pdf[[\"Stn_Name\",\"Tx\",\"Tm\",\"Clus_Db\"]].head(5)\n",
        "\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "%matplotlib inline\n",
        "rcParams['figure.figsize'] = (14,10)\n",
        "\n",
        "my_map = Basemap(projection='merc',\n",
        "            resolution = 'l', area_thresh = 1000.0,\n",
        "            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
        "            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n",
        "\n",
        "my_map.drawcoastlines()\n",
        "my_map.drawcountries()\n",
        "#my_map.drawmapboundary()\n",
        "my_map.fillcontinents(color = 'white', alpha = 0.3)\n",
        "my_map.shadedrelief()\n",
        "\n",
        "# To create a color map\n",
        "colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))\n",
        "\n",
        "\n",
        "\n",
        "#Visualization1\n",
        "for clust_number in set(labels):\n",
        "    c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])\n",
        "    clust_set = pdf[pdf.Clus_Db == clust_number]                    \n",
        "    my_map.scatter(clust_set.xm, clust_set.ym, color =c,  marker='o', s= 20, alpha = 0.85)\n",
        "    if clust_number != -1:\n",
        "        cenx=np.mean(clust_set.xm) \n",
        "        ceny=np.mean(clust_set.ym) \n",
        "        plt.text(cenx,ceny,str(clust_number), fontsize=25, color='red',)\n",
        "        print (\"Cluster \"+str(clust_number)+', Avg Temp: '+ str(np.mean(clust_set.Tm)))\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}